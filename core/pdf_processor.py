import pdfplumber
import chromadb
from chromadb.utils import embedding_functions
import os
from openai import OpenAI

class PDFKnowledgeBase:
    def __init__(self, api_key, collection_name, persist_directory="./storage/vector_store"):
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key)
        
        # 1. Kh·ªüi t·∫°o ChromaDB Client
        self.chroma_client = chromadb.PersistentClient(path=persist_directory)
        
        # 2. S·ª≠ d·ª•ng OpenAI Embedding Function cho Chroma
        # N√≥ s·∫Ω t·ª± ƒë·ªông g·ªçi API 'text-embedding-3-small' khi th√™m/t√¨m d·ªØ li·ªáu
        self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
            api_key=api_key,
            model_name="text-embedding-3-small"
        )
        
        # 3. T·∫°o ho·∫∑c l·∫•y Collection
        self.collection = self.chroma_client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_fn
        )

    def process_and_store_pdf(self, pdf_path):
        """
        ƒê·ªçc t·ª´ng trang PDF v√† l∆∞u v√†o Vector DB.
        """
        print(f"üìÑ ƒêang x·ª≠ l√Ω PDF: {pdf_path}")
        
        # D√πng pdfplumber ƒë·ªÉ tr√≠ch xu·∫•t text t·ªët h∆°n
        with pdfplumber.open(pdf_path) as pdf:
            documents = []
            metadatas = []
            ids = []
            
            for i, page in enumerate(pdf.pages):
                # 1. Tr√≠ch xu·∫•t text t·ª´ trang
                text = page.extract_text()
                if not text: 
                    text = "" # X·ª≠ l√Ω trang ch·ªâ c√≥ ·∫£nh (n·∫øu c·∫ßn OCR th√¨ ph·∫£i d√πng th∆∞ vi·ªán kh√°c)
                
                # L√†m s·∫°ch text c∆° b·∫£n
                text = text.strip()
                
                # 2. (Optional) N·∫øu mu·ªën ph√¢n t√≠ch c·∫£ ·∫¢NH:
                # ·ªû b∆∞·ªõc n√†y b·∫°n c√≥ th·ªÉ convert page -> image, g·ª≠i l√™n GPT-4o Vision 
                # ƒë·ªÉ l·∫•y m√¥ t·∫£ ·∫£nh, r·ªìi c·ªông v√†o bi·∫øn `text`.
                # Tuy nhi√™n, ƒë·ªÉ ti·∫øt ki·ªám, ta d√πng text tr√≠ch xu·∫•t l√† ƒë·ªß cho MVP.
                
                if len(text) > 10: # Ch·ªâ l∆∞u trang c√≥ n·ªôi dung ƒë√°ng k·ªÉ
                    page_num = i + 1
                    
                    # Chu·∫©n b·ªã d·ªØ li·ªáu cho Chroma
                    documents.append(text)
                    
                    # Metadata c·ª±c k·ª≥ quan tr·ªçng ƒë·ªÉ map ng∆∞·ª£c l·∫°i
                    metadatas.append({
                        "source": os.path.basename(pdf_path),
                        "page_number": page_num
                    })
                    
                    # ID duy nh·∫•t
                    ids.append(f"{os.path.basename(pdf_path)}_page_{page_num}")
            
            # 3. L∆∞u Batch v√†o ChromaDB
            if documents:
                print(f"üíæ ƒêang l∆∞u {len(documents)} trang v√†o Vector DB...")
                self.collection.upsert(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
                print("‚úÖ ƒê√£ l∆∞u xong PDF.")
            else:
                print("‚ö†Ô∏è PDF kh√¥ng c√≥ text tr√≠ch xu·∫•t ƒë∆∞·ª£c.")

    def find_relevant_pages(self, transcript_chunk, n_results=2):
        """
        Input: M·ªôt ƒëo·∫°n transcript (l·ªùi n√≥i)
        Output: N·ªôi dung c√°c trang PDF li√™n quan nh·∫•t
        """
        results = self.collection.query(
            query_texts=[transcript_chunk],
            n_results=n_results
        )
        
        # Format k·∫øt qu·∫£ tr·∫£ v·ªÅ cho d·ªÖ d√πng
        relevant_context = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                meta = results['metadatas'][0][i]
                relevant_context.append({
                    "text": doc,
                    "page": meta['page_number'],
                    "source": meta['source']
                })
        
        return relevant_context