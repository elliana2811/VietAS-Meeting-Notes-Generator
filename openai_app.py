import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import queue
import time
import logging
import os
import uuid
import soundfile as sf
import librosa

# --- IMPORT MODULES ---
from core.vad import VADDetector
from core.audio_processor import RealTimeAudioProcessor
from core.punctuation import restore_punctuation
from core.openai_asr import OpenAIASRService 
from core.diarization import OfflineDiarizer 
from core.pdf_processor import PDFKnowledgeBase
from core.rag_service import MeetingMinuteGenerator

# C·∫•u h√¨nh Log ƒë·ªÉ in ra Terminal ƒë·∫πp h∆°n
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

st.set_page_config(page_title="AI Meeting Assistant", layout="wide")
st.title("üéôÔ∏è AI Meeting Assistant (Traceable RAG)")

# --- C·∫§U H√åNH API KEYS ---
if "OPENAI_API_KEY" in st.secrets:
    API_KEY = st.secrets["OPENAI_API_KEY"]
else:
    st.error("üö® Ch∆∞a t√¨m th·∫•y OPENAI_API_KEY")
    st.stop()

if "HF_TOKEN" in st.secrets:
    HF_TOKEN = st.secrets["HF_TOKEN"]
else:
    HF_TOKEN = None

# Session ID
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# CSS
st.markdown("""
<style>
    .draft-box { padding: 10px; background-color: #f0f2f6; border: 1px dashed #ccc; margin-bottom: 5px;}
    .final-box { padding: 15px; border-left: 5px solid #00cc66; background-color: #fff; margin-bottom: 10px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    .log-box { font-family: monospace; font-size: 12px; background: #333; color: #0f0; padding: 10px; border-radius: 5px; }
</style>
""", unsafe_allow_html=True)

# --- 1. LOAD SERVICES ---
@st.cache_resource
def _get_core_services_cached(session_id):
    print(f"\nüöÄ [SYSTEM] KH·ªûI T·∫†O SERVICES CHO SESSION: {session_id}")
    vad = VADDetector()
    asr = OpenAIASRService(api_key=API_KEY)
    diarizer = OfflineDiarizer(hf_token=HF_TOKEN) if HF_TOKEN else None
    
    # PDF Service
    pdf_kb = PDFKnowledgeBase(api_key=API_KEY, collection_name=f"meeting_{session_id}")
    
    # RAG Service
    rag_gen = MeetingMinuteGenerator(api_key=API_KEY)
    
    restore_punctuation("", force_flush=False)
    return vad, asr, diarizer, pdf_kb, rag_gen

def load_core_services():
    with st.spinner("ƒêang kh·ªüi ƒë·ªông AI Models..."):
        models = _get_core_services_cached(st.session_state.session_id)
    return models

vad_model, asr_model, diarizer_model, pdf_service, rag_service = load_core_services()

# --- 2. STATE MANAGEMENT ---
if "transcript_history" not in st.session_state: st.session_state.transcript_history = ""
if "full_transcript" not in st.session_state: st.session_state.full_transcript = [] 
if "pdf_processed" not in st.session_state: st.session_state.pdf_processed = False
if "pdf_name" not in st.session_state: st.session_state.pdf_name = ""

def clear_session():
    st.session_state.transcript_history = ""
    st.session_state.full_transcript = []
    st.session_state.final_minutes = ""
    restore_punctuation("", force_flush=True)
    st.toast("ƒê√£ x√≥a d·ªØ li·ªáu c≈©!", icon="üóëÔ∏è")

# --- 3. UI SIDEBAR (PDF FLOW) ---
with st.sidebar:
    st.header("1. T√†i li·ªáu (PDF)")
    uploaded_pdf = st.file_uploader("Upload PDF", type="pdf")
    
    # X·ª≠ l√Ω PDF
    if uploaded_pdf:
        # Ki·ªÉm tra n·∫øu file m·ªõi kh√°c file c≈© ho·∫∑c ch∆∞a process
        if uploaded_pdf.name != st.session_state.pdf_name:
            st.info(f"üîÑ ƒêang x·ª≠ l√Ω PDF: {uploaded_pdf.name}...")
            print(f"\nüìÑ [PDF FLOW] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {uploaded_pdf.name}")
            
            pdf_path = f"temp_{st.session_state.session_id}.pdf"
            with open(pdf_path, "wb") as f:
                f.write(uploaded_pdf.getbuffer())
            
            # G·ªçi service x·ª≠ l√Ω
            pdf_service.process_and_store_pdf(pdf_path)
            
            # C·∫≠p nh·∫≠t State
            st.session_state.pdf_processed = True
            st.session_state.pdf_name = uploaded_pdf.name
            
            if os.path.exists(pdf_path): os.remove(pdf_path)
            print(f"‚úÖ [PDF FLOW] Ho√†n t·∫•t vector h√≥a PDF.\n")
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i PDF
    if st.session_state.pdf_processed:
        st.success(f"‚úÖ ƒê√£ h·ªçc: {st.session_state.pdf_name}")
    else:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ t√†i li·ªáu tham kh·∫£o.")

    st.divider()
    if st.button("üóëÔ∏è Reset Cu·ªôc h·ªçp"):
        clear_session()
        st.rerun()

# --- 4. MAIN UI (AUDIO FLOW) ---
tab1, tab2 = st.tabs(["üéôÔ∏è Real-time", "üéß Upload File"])

# Helper functions
def add_to_transcript(text, speaker):
    color = {"SPEAKER_00": "#00cc66", "SPEAKER_01": "#0099ff", "Ng∆∞·ªùi n√≥i": "#999999"}.get(speaker, "#333333")
    st.session_state.transcript_history += f"<div class='final-box' style='border-left-color: {color};'><b style='color:{color}'>{speaker}:</b> {text}</div>"
    st.session_state.full_transcript.append({"speaker": speaker, "text": text})

def process_chunk_logic(audio_chunk):
    # 1. Diarization
    speaker = "Ng∆∞·ªùi n√≥i"
    if diarizer_model:
        try:
            temp_wav = "temp_proc.wav"
            sf.write(temp_wav, audio_chunk, 16000)
            diar = diarizer_model.process_file(temp_wav)
            # Dominant speaker logic
            segs = diar.get("speaker_segments", [])
            if segs:
                durations = {}
                for s in segs: durations[s['speaker']] = durations.get(s['speaker'], 0) + (s['end'] - s['start'])
                speaker = max(durations, key=durations.get)
            if os.path.exists(temp_wav): os.remove(temp_wav)
        except: pass
    
    # 2. ASR
    raw_text = ""
    if asr_model:
        res = asr_model.predict(audio_chunk)
        raw_text = res.get('text', '').strip()
    
    # 3. Punctuation & Add
    if raw_text:
        punct = restore_punctuation(raw_text, force_flush=False)
        if punct:
            add_to_transcript(punct['punctuated_text'], speaker)
        return raw_text # Tr·∫£ v·ªÅ ƒë·ªÉ bi·∫øt c√≥ text hay kh√¥ng
    return None

# --- TAB 1: REAL-TIME ---
with tab1:
    col_l, col_r = st.columns([1, 2])
    with col_l:
        def factory(): return RealTimeAudioProcessor(vad_model=vad_model)
        ctx = webrtc_streamer(key="rec", mode=WebRtcMode.SENDONLY, audio_processor_factory=factory,
                              rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})
    with col_r:
        chat_box = st.container()
        status_txt = st.empty()
        with chat_box: st.markdown(st.session_state.transcript_history, unsafe_allow_html=True)
        
        if ctx.state.playing:
            while True:
                if ctx.audio_processor:
                    try:
                        chunk = ctx.audio_processor.output_queue.get_nowait()
                        status_txt.info("‚ö° ƒêang x·ª≠ l√Ω...")
                        res = process_chunk_logic(chunk)
                        if res: 
                            with chat_box: st.markdown(st.session_state.transcript_history, unsafe_allow_html=True)
                            status_txt.empty()
                    except queue.Empty:
                        time.sleep(0.1)

# ================= TAB 2: UPLOAD AUDIO FILE (S·ª¨A L·∫†I) =================
with tab2:
    st.info("T·∫£i l√™n file ghi √¢m cu·ªôc h·ªçp (.wav, .mp3) ƒë·ªÉ x·ª≠ l√Ω.")
    audio_file = st.file_uploader("Ch·ªçn file audio", type=["wav", "mp3", "m4a"])
    
    if audio_file:
        st.audio(audio_file)
        if st.button("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω File"):
            # Clear data c≈©
            clear_session()
            print(f"\nüéß [AUDIO FLOW] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file audio: {audio_file.name}")
            
            with st.spinner("ƒêang t·∫£i v√† ph√¢n t√≠ch file..."):
                # 1. Load file
                y, sr = librosa.load(audio_file, sr=16000)
                
                # 2. Smart Splitting (C·∫Øt b·ªè kho·∫£ng l·∫∑ng)
                # top_db=25: C√°c √¢m thanh nh·ªè h∆°n 25dB so v·ªõi peak s·∫Ω b·ªã coi l√† im l·∫∑ng
                # frame_length, hop_length: C·∫•u h√¨nh c·ª≠a s·ªï qu√©t
                non_silent_intervals = librosa.effects.split(y, top_db=25, frame_length=2048, hop_length=512)
                
                total_segments = len(non_silent_intervals)
                print(f"‚úÇÔ∏è ƒê√£ c·∫Øt th√†nh {total_segments} ƒëo·∫°n h·ªôi tho·∫°i (b·ªè qua kho·∫£ng l·∫∑ng).")
                
                status_bar = st.progress(0)
                status_text = st.empty()
                chat_box_file = st.container()
                
                # Bi·∫øn l∆∞u context ƒë·ªÉ g·ª≠i cho Whisper (gi√∫p n·ªëi t·ª´ t·ªët h∆°n)
                previous_context = ""
                
                # 3. Duy·ªát qua t·ª´ng ƒëo·∫°n h·ªôi tho·∫°i th·ª±c s·ª±
                for i, (start, end) in enumerate(non_silent_intervals):
                    # L·∫•y ƒëo·∫°n audio
                    chunk = y[start:end]
                    
                    # N·∫øu ƒëo·∫°n qu√° ng·∫Øn (< 0.5s) th√¨ b·ªè qua
                    duration = (end - start) / sr
                    if duration < 0.5:
                        continue
                        
                    # Hi·ªÉn th·ªã log
                    status_text.text(f"ƒêang x·ª≠ l√Ω ƒëo·∫°n {i+1}/{total_segments} ({duration:.1f}s)...")
                    if i % 5 == 0: print(f"   ‚è≥ [AUDIO] Processing segment {i+1}/{total_segments}")
                    
                    # --- G·ªåI X·ª¨ L√ù (S·ª¨A L·∫†I LOGIC G·ªåI) ---
                    # Logic t√°ch ra ƒë·ªÉ truy·ªÅn previous_context v√†o
                    
                    # A. Diarization (V·∫´n ch·∫°y nh∆∞ c≈©)
                    speaker = "Ng∆∞·ªùi n√≥i"
                    if diarizer_model:
                        try:
                            temp_wav = "temp_proc.wav"
                            sf.write(temp_wav, chunk, 16000)
                            diar = diarizer_model.process_file(temp_wav)
                            segs = diar.get("speaker_segments", [])
                            if segs:
                                durations = {}
                                for s in segs: durations[s['speaker']] = durations.get(s['speaker'], 0) + (s['end'] - s['start'])
                                speaker = max(durations, key=durations.get)
                            if os.path.exists(temp_wav): os.remove(temp_wav)
                        except: pass
                    
                    # B. ASR (OpenAI) - TRUY·ªÄN TH√äM PREVIOUS CONTEXT
                    raw_text = ""
                    if asr_model:
                        # L∆∞u √Ω: method predict c·∫ßn update ·ªü core/openai_asr.py ƒë·ªÉ nh·∫≠n tham s·ªë th·ª© 2
                        res = asr_model.predict(chunk, previous_text=previous_context)
                        raw_text = res.get('text', '').strip()
                    
                    # C. Update UI & Context
                    if raw_text:
                        # C·∫≠p nh·∫≠t context cho v√≤ng l·∫∑p sau
                        previous_context = raw_text 
                        
                        punct = restore_punctuation(raw_text, force_flush=False)
                        if punct:
                            add_to_transcript(punct['punctuated_text'], speaker)
                            with chat_box_file: 
                                st.markdown(st.session_state.transcript_history, unsafe_allow_html=True)
                    
                    # Update Progress
                    status_bar.progress((i + 1) / total_segments)
            
            # Flush cu·ªëi c√πng
            flush = restore_punctuation("", force_flush=True)
            if flush:
                add_to_transcript(flush['punctuated_text'], "End")
                
            st.success("‚úÖ ƒê√£ x·ª≠ l√Ω xong File!")
            with chat_box_file:
                st.markdown(st.session_state.transcript_history, unsafe_allow_html=True)

# --- 5. RAG GENERATION (LOGIC GH√âP N·ªêI) ---
st.divider()
st.subheader("üìù T·∫°o bi√™n b·∫£n & RAG Log")

if st.button("ü§ñ T·∫°o Bi√™n b·∫£n th√¥ng minh"):
    if not st.session_state.full_transcript:
        st.warning("Ch∆∞a c√≥ n·ªôi dung h·ªôi tho·∫°i!")
    else:
        print("\n==================================================")
        print("ü§ñ [RAG START] B·∫ÆT ƒê·∫¶U QUY TR√åNH T·∫†O BI√äN B·∫¢N")
        print(f"üìä T·ªïng s·ªë c√¢u h·ªôi tho·∫°i: {len(st.session_state.full_transcript)}")
        print(f"üìö Tr·∫°ng th√°i PDF: {'ƒê√£ c√≥' if st.session_state.pdf_processed else 'Kh√¥ng c√≥'}")
        print("==================================================\n")

        full_summary = ""
        
        # 1. Convert transcript to text lines
        raw_lines = [f"{x['speaker']}: {x['text']}" for x in st.session_state.full_transcript]
        
        # 2. Chunking Transcript (Gom 10 c√¢u l√†m 1 chunk ƒë·ªÉ query)
        chunk_size = 10
        trans_chunks = ["\n".join(raw_lines[i:i+chunk_size]) for i in range(0, len(raw_lines), chunk_size)]
        
        rag_progress = st.progress(0)
        
        for idx, t_chunk in enumerate(trans_chunks):
            print(f"\n--- üîÑ [CHUNK {idx+1}/{len(trans_chunks)}] X·ª¨ L√ù ƒêO·∫†N H·ªòI THO·∫†I ---")
            print(f"üìù N·ªôi dung chunk (r√∫t g·ªçn): {t_chunk[:100].replace(chr(10), ' ')}...")
            
            # 3. Retrieval (T√¨m ki·∫øm PDF)
            relevant_pages = []
            if st.session_state.pdf_processed:
                print(f"üîé [RETRIEVAL] ƒêang t√¨m ki·∫øm trong ChromaDB...")
                relevant_pages = pdf_service.find_relevant_pages(t_chunk)
                
                if relevant_pages:
                    print(f"‚úÖ [FOUND] T√¨m th·∫•y {len(relevant_pages)} ng·ªØ c·∫£nh li√™n quan:")
                    for p in relevant_pages:
                        print(f"    - [Trang {p['page']}]: {p['text'][:80]}...")
                else:
                    print("‚ö†Ô∏è [NOT FOUND] Kh√¥ng t√¨m th·∫•y th√¥ng tin kh·ªõp trong PDF.")
            else:
                print("‚è≠Ô∏è [SKIP] Kh√¥ng c√≥ PDF, b·ªè qua b∆∞·ªõc Retrieval.")

            # 4. Generation (G·ªçi LLM)
            print(f"üß† [LLM] ƒêang g·ª≠i prompt t·ªõi OpenAI...")
            res = rag_service.generate_minute_with_rag(t_chunk, relevant_pages)
            print(f"‚úÖ [DONE] LLM ƒë√£ tr·∫£ v·ªÅ t√≥m t·∫Øt cho chunk n√†y.")
            
            # 5. Gh√©p k·∫øt qu·∫£
            full_summary += f"\n#### Ph·∫ßn {idx+1}\n{res['summary']}\n"
            if res['ref_pages']:
                full_summary += f"*(Ngu·ªìn tham kh·∫£o: Trang {res['ref_pages']})*\n"
            
            rag_progress.progress((idx+1)/len(trans_chunks))
        
        print("\n==================================================")
        print("‚úÖ [RAG FINISH] ƒê√É T·∫†O XONG BI√äN B·∫¢N")
        print("==================================================\n")
        
        st.session_state.final_minutes = full_summary
        st.success("ƒê√£ t·∫°o bi√™n b·∫£n xong! Ki·ªÉm tra Terminal ƒë·ªÉ xem chi ti·∫øt log.")

if "final_minutes" in st.session_state and st.session_state.final_minutes:
    st.markdown("---")
    st.markdown("### üìã K·∫æT QU·∫¢ BI√äN B·∫¢N")
    st.markdown(st.session_state.final_minutes)